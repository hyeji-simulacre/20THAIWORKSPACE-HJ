# 03. 커스텀 스크래핑 (Custom Scraping) - 웹상의 모든 데이터를 내 것으로!

> **"Ctrl+C, Ctrl+V는 이제 그만. AI에게 '긁어와'라고 말하세요."**

## 1. 🎯 개념 및 필요성 (Concept)

### 🧐 이게 뭐죠?
웹사이트에 있는 정보(뉴스, 가격, 댓글, 공지사항 등)를 자동으로 수집하는 **'로봇(Bot)'**을 만드는 기술입니다. 우리는 복잡한 코딩 대신 AI에게 "이거 가져와"라고 시키면 AI가 알아서 로봇을 만들어줍니다.

### 💡 왜 배워야 하죠?
- **노가다 해방**: 매일 아침 경쟁사 가격 확인, 뉴스 검색... 1시간 걸리던 일을 버튼 한 번으로 끝냅니다.
- **실시간 감시**: 내가 자는 동안에도 로봇은 웹사이트를 지켜보다가 변화가 생기면 알려줄 수 있습니다.
- **대량 수집**: 사람 손으로 100개 복사하면 손가락 아프지만, 로봇은 100만 개도 군말 없이 가져옵니다.

---

## 2. 🚀 이용 방법 (How-to)

이 스킬은 조금 특별합니다. 명령어가 아니라 **Claude Code에게 말(채팅)로** 시킵니다.

### 1️⃣ Claude Code에게 말 걸기
터미널에서 `claude` 엔터 치고 대화를 시작하세요.

### 2️⃣ 요청하기 (마법의 주문)
```text
"네이버 증권에서 [삼성전자] 주가랑 관련 뉴스 제목 5개만 크롤링하는 코드 짜줘."
```
또는
```text
"이 사이트(URL)에 있는 채용 공고 리스트를 엑셀로 저장하고 싶어. 스크래핑 해줘."
```

### 3️⃣ AI의 질문에 대답하기
AI가 똑똑해서 더 정확히 하려고 물어볼 겁니다.
- *"뉴스 제목만 가져올까요, 내용도 가져올까요?"*
- *"몇 페이지까지 긁을까요?"*

-> 원하는 대로 대답해주면, AI가 **즉석에서 프로그램을 코딩해서 실행**해줍니다!

---

## 3. 🤖 프로세스 이해하기 (Process)

1. **분석 (Explore)**: AI가 먼저 사이트에 가서 구조를 봅니다. "아, 제목은 여기 있고 가격은 저기 숨어있네."
2. **제작 (Generate)**: 정보를 쏙쏙 빼내는 맞춤형 도구(Python 코드)를 짭니다.
3. **수집 (Collect)**: 도구를 실행해서 데이터를 긁어모아 파일(`csv`, `json`)로 저장합니다.

### 🏭 지식 관리 시스템에서의 위치
- **저장 위치**: `30-collected/31-web-scraps/`
- **이동**: 프로젝트에 필요한 자료면 `10-working/{프로젝트명}/`으로 옮겨 관리합니다.
- **역할**: 웹상의 "휘발성 정보"를 내 컴퓨터의 "영구적 자산"으로 만듭니다.

---

## 4. 💼 직무별 활용 사례 (Use Case)

### 📢 홍보/PR 담당자 - "네티즌 여론 조사관"
- **상황**: 우리 회사 신제품에 대한 커뮤니티, 블로그 반응을 모아야 함.
- **전**: 각종 사이트 돌아다니며 검색하고 캡처하고 엑셀에 정리.
- **후**: "주요 커뮤니티에서 [제품명] 검색해서 게시글 제목이랑 조회수 긁어와" → **여론 분석 리포트 자동 생성**.

### 🛍️ 쇼핑몰 MD - "최저가 탐지기"
- **상황**: 경쟁사 A, B, C가 가격을 내렸는지 매일 확인해야 함.
- **전**: 즐겨찾기 해둔 사이트 50개 매일 아침마다 클릭질.
- **후**: "경쟁사 베스트 상품 50개 가격 매일 아침 9시에 긁어서 엑셀로 줘" → **가격 변동 알람**.

### 💼 HR 채용 담당자 - "인재 발굴단"
- **상황**: 링크드인이나 채용 사이트에서 특정 기술을 가진 개발자를 찾아야 함.
- **전**: 키워드 검색 후 무한 스크롤 내리며 프로필 확인.
- **후**: "채용 사이트에서 'Python', 'AI' 키워드 있는 이력서 정보 수집해줘" → **인재 풀(Pool) 자동 구축**.

### 🏪 소상공인/자영업자 D씨 - "우리 동네 리뷰 관리"
- **상황**: 배달 앱, 지도 앱에 달린 우리 가게 리뷰를 모아서 분석하고 싶음.
- **후**: "네이버지도 우리 가게 리뷰 최신순으로 100개 긁어와" → Claude에게 "긍정/부정 리뷰 분류하고, 불만 사항 핵심 3가지만 알려줘" → **서비스 개선**.

---

## 5. 🍯 꿀팁: Claude에게 뭐라고 질문하나요? (Prompt)

스크래핑을 시킬 때는 **"육하원칙"**을 생각하세요.

> **"누가":** (생략 가능, Claude가 함)
> **"어디서":** [URL 주소] 에서
> **"무엇을":** [상품명, 가격, 리뷰 수] 데이터를
> **"어떻게":** [엑셀 파일로] 저장해줘.
> **"왜":** (생략 가능)
> **"언제":** (지금 당장!)

**실전 프롬프트 예시:**
`"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105 여기 있는 '헤드라인 뉴스' 제목이랑 링크만 10개 뽑아서 마크다운 표로 만들어줘."`


---

**⚠️ 주의사항**: 
웹 스크래핑은 강력하지만 책임이 따릅니다. 
1. **`robots.txt` 준수**: AI가 "이 사이트는 수집하면 안 돼요"라고 경고하면 멈추세요.
2. **서버 부하 주의**: 너무 빠르게 많이 긁으면 사이트가 아파하거나 내 IP를 차단할 수 있습니다. (AI가 알아서 조절하지만, 욕심은 금물!)
